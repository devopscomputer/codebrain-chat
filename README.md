# ğŸ§  CodeBrain Chat â€” AI Dev Assistant Sem Filtro

CodeBrain Ã© um projeto de chat inteligente **voltado exclusivamente para programadores**, alimentado por **modelos de IA open-source locais** (como Mistral, Deepseek ou Code Llama), com dados filtrados de alto valor tÃ©cnico (Stack Overflow, GitHub, RFCs, MDN).

---

## ğŸš€ VisÃ£o Geral

- ğŸ’» **IA especialista para devs**
- ğŸ” **Respostas tÃ©cnicas profundas** com contexto
- âŒ **Sem censura**: comandos avanÃ§ados como `/modo_hacker`, `/refactor`, `/doc`
- ğŸ“š **Big Data tÃ©cnico filtrado** indexado com LangChain + FAISS
- ğŸ§  **LLMs locais** via Ollama ou Llama.cpp (offline-ready)
- ğŸ“¦ API FastAPI robusta, modular, pronta para produÃ§Ã£o
- âš™ï¸ Pipeline RAG com suporte a **filtros por linguagem, versÃ£o, stack**

---

## ğŸ—‚ Estrutura do Projeto

### ğŸ“ Frontend (`/codebrain-chat`)

| Arquivo           | DescriÃ§Ã£o                                |
|-------------------|-------------------------------------------|
| `index.html`      | Interface inicial responsiva e leve       |
| `style.css`       | Dark mode dev-friendly, layout terminal   |
| `script.js`       | Envia mensagem, processa mock/resposta    |
| `mock-responses`  | Simula IA antes da conexÃ£o real           |

### ğŸ“ Backend (`/codebrain-backend`)

| DiretÃ³rio         | DescriÃ§Ã£o                                                       |
|-------------------|-----------------------------------------------------------------|
| `app/main.py`     | Entrypoint FastAPI                                              |
| `router/chat.py`  | Endpoint `/api/chat` para receber mensagens                     |
| `core/model.py`   | Conecta com Ollama ou Llama.cpp                                 |
| `core/chain.py`   | Pipeline LangChain + contexto tÃ©cnico via embeddings            |
| `core/prompts.py` | Interpreta comandos (`/modo_hacker`, etc.)                      |
| `utils/logger.py` | Logs organizados no estilo DevSecOps                            |
| `data/`           | Dumps tÃ©cnicos (StackOverflow, MDN, GitHub)                     |
| `embeddings/`     | Ãndice vetorial FAISS para busca semÃ¢ntica                     |

---

## âš™ï¸ InstalaÃ§Ã£o RÃ¡pida (modo dev)

```bash
cd codebrain-backend
python -m venv venv
.\venv\Scripts\activate     # ou source venv/bin/activate no Linux
pip install -r requirements.txt
uvicorn app.main:app --reload
ğŸ”— Endpoint de API
POST /api/chat

json
Copiar
Editar
{
  "message": "Como usar OAuth2 com Node.js?",
  "context": {
    "language": "Node",
    "version": "18.0.0"
  }
}
âœ¨ Comandos Especiais
Comando	FunÃ§Ã£o
/modo_hacker	Ativa respostas voltadas Ã  engenharia reversa
/refactor	IA melhora e reestrutura cÃ³digos enviados
/doc	Busca documentos tÃ©cnicos por linguagem/tag
/explain	ExplicaÃ§Ãµes passo a passo
/snippet	Responde sÃ³ com cÃ³digo direto, sem explicaÃ§Ã£o
ğŸ’¥ Diferenciais TÃ©cnicos (para recrutadores)
âœ… Backend desacoplado, modular, escalÃ¡vel

âœ… API RESTful documentada e limpa

âœ… Prompt engineering contextualizado

âœ… LLMs open-source com controle total

âœ… Suporte Ã  RAG com FAISS (custom retrieval)

âœ… Pronto para deploy com Docker / CI/CD / monitoramento

âœ… SeguranÃ§a: sem dependÃªncia externa de OpenAI ou Anthropic

ğŸ§± Stack Utilizada
ğŸ§  FastAPI + Uvicorn

ğŸ§  LLama.cpp / Ollama (modelo local)

ğŸ§  LangChain + FAISS

ğŸ“¡ Requests/HTTPX para integraÃ§Ã£o com LLM

ğŸ“¦ Python 3.10+, venv, .env, dotenv, requirements.txt

ğŸ“Š Dumps reais tÃ©cnicos de Stack Overflow, MDN, GitHub

ğŸ“ Roadmap (v1.0 â†’ v2.0)
 Estrutura completa backend + frontend

 API conectada Ã  IA local via Ollama

 Prompt e filtros por linguagem

 Chat UI com streaming real-time

 Modo mobile (React Native)

 Painel de usuÃ¡rios (devs)

 HistÃ³rico, favoritos, pastas

 CI/CD via GitHub Actions

 Dockerfile com IA embutida

ğŸ“œ LicenÃ§a
MIT â€” projeto educacional/open-source.

ğŸ¤ Contato / Parcerias
Desenvolvido por Paulo Silas
Tech Lead | Especialista em automaÃ§Ã£o, IA, backend e seguranÃ§a
ğŸ”— GitHub: @devopscomputer

